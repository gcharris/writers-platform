"""Agent pool initializer for Writers Factory.

This module provides factory functions to initialize and configure the agent pool
with available LLM providers.

Supports:
- Cloud providers (via environment variables): Claude, GPT, Gemini, Grok
- Local models: Ollama (FREE)
- Chinese providers: DeepSeek, Qwen, Doubao, etc.
"""

import logging
import os
from typing import Optional

from app.core.agent_pool import AgentPool
from app.services.agents.base_agent import BaseAgent, AgentConfig

logger = logging.getLogger(__name__)


# ============================================================================
# Mock Cloud Agents (Temporary - Replace with real implementations)
# ============================================================================

class MockCloudAgent(BaseAgent):
    """Temporary mock agent for cloud providers.

    This is a placeholder that returns mock generations until real cloud
    agent implementations are created.
    """

    async def generate(
        self,
        prompt: str,
        temperature: float = 0.8,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> dict:
        """Generate mock response.

        Returns:
            Dict with mock generation result
        """
        # Mock generation for testing
        mock_output = f"""# Generated Scene (Mock - {self.name})

[This is a mock response from {self.name}. In production, this would be
generated by the actual {self.model} model via API.]

The scene begins...

Based on the provided outline:
{prompt[:200]}...

[End of mock generation. Replace with real API integration.]
"""

        # Estimate tokens (rough)
        tokens_input = len(prompt.split()) * 1.3
        tokens_output = len(mock_output.split()) * 1.3

        # Calculate mock cost
        cost = (
            (tokens_input / 1000) * self.config.cost_per_1k_input +
            (tokens_output / 1000) * self.config.cost_per_1k_output
        )

        return {
            "output": mock_output,
            "tokens_input": int(tokens_input),
            "tokens_output": int(tokens_output),
            "cost": cost,
            "model_version": self.model,
            "metadata": {
                "mock": True,
                "temperature": temperature,
                "max_tokens": max_tokens
            }
        }


# ============================================================================
# Agent Pool Initializer
# ============================================================================

def create_agent_pool(
    enable_cloud: bool = True,
    enable_local: bool = True,
    enable_chinese: bool = False
) -> AgentPool:
    """Create and configure an agent pool with available providers.

    Args:
        enable_cloud: Enable cloud providers (Claude, GPT, Gemini)
        enable_local: Enable local Ollama if available
        enable_chinese: Enable Chinese providers (DeepSeek, Qwen, etc.)

    Returns:
        Configured AgentPool instance

    Environment Variables (for cloud providers):
        - ANTHROPIC_API_KEY: Claude models
        - OPENAI_API_KEY: GPT models
        - GOOGLE_API_KEY: Gemini models
        - XAI_API_KEY: Grok models
        - DEEPSEEK_API_KEY: DeepSeek models
    """
    pool = AgentPool()

    # ========================================================================
    # Cloud Providers (Mock for now - TODO: Implement real agents)
    # ========================================================================

    if enable_cloud:
        # Claude Sonnet 4.5 (default model)
        if os.getenv("ANTHROPIC_API_KEY"):
            config = AgentConfig(
                name="claude-sonnet-4.5",
                model="claude-sonnet-4-20250514",
                api_key=os.getenv("ANTHROPIC_API_KEY"),
                base_url="https://api.anthropic.com/v1",
                context_window=200_000,
                max_output=8192,
                cost_per_1k_input=0.003,  # $3 per million input tokens
                cost_per_1k_output=0.015,  # $15 per million output tokens
                timeout=120
            )
            agent = MockCloudAgent(config)
            pool.register_agent("claude-sonnet-4.5", agent, enabled=True)
            logger.info("Registered Claude Sonnet 4.5 (mock)")
        else:
            logger.warning("ANTHROPIC_API_KEY not set, Claude unavailable")

        # GPT-4o
        if os.getenv("OPENAI_API_KEY"):
            config = AgentConfig(
                name="gpt-4o",
                model="gpt-4o-2024-11-20",
                api_key=os.getenv("OPENAI_API_KEY"),
                base_url="https://api.openai.com/v1",
                context_window=128_000,
                max_output=4096,
                cost_per_1k_input=0.0025,  # $2.50 per million input tokens
                cost_per_1k_output=0.010,  # $10 per million output tokens
                timeout=120
            )
            agent = MockCloudAgent(config)
            pool.register_agent("gpt-4o", agent, enabled=True)
            logger.info("Registered GPT-4o (mock)")
        else:
            logger.warning("OPENAI_API_KEY not set, GPT unavailable")

        # Gemini 2.0 Flash
        if os.getenv("GOOGLE_API_KEY"):
            config = AgentConfig(
                name="gemini-2-flash",
                model="gemini-2.0-flash-exp",
                api_key=os.getenv("GOOGLE_API_KEY"),
                base_url="https://generativelanguage.googleapis.com/v1beta",
                context_window=1_000_000,
                max_output=8192,
                cost_per_1k_input=0.0,  # Free tier
                cost_per_1k_output=0.0,
                timeout=120
            )
            agent = MockCloudAgent(config)
            pool.register_agent("gemini-2-flash", agent, enabled=True)
            logger.info("Registered Gemini 2.0 Flash (mock)")
        else:
            logger.warning("GOOGLE_API_KEY not set, Gemini unavailable")

        # Grok 2
        if os.getenv("XAI_API_KEY"):
            config = AgentConfig(
                name="grok-2",
                model="grok-2-1212",
                api_key=os.getenv("XAI_API_KEY"),
                base_url="https://api.x.ai/v1",
                context_window=128_000,
                max_output=4096,
                cost_per_1k_input=0.002,  # $2 per million input tokens
                cost_per_1k_output=0.010,  # $10 per million output tokens
                timeout=120
            )
            agent = MockCloudAgent(config)
            pool.register_agent("grok-2", agent, enabled=True)
            logger.info("Registered Grok 2 (mock)")
        else:
            logger.warning("XAI_API_KEY not set, Grok unavailable")

    # ========================================================================
    # Local Models (FREE via Ollama)
    # ========================================================================

    if enable_local:
        from app.services.agents.ollama_agent import OllamaAgent, get_ollama_agent

        if OllamaAgent.is_available():
            # Llama 3.3 70B (best local model)
            ollama_agent = get_ollama_agent("llama3.3")
            if ollama_agent:
                # Wrap Ollama agent to match pool interface
                class OllamaWrapper(BaseAgent):
                    """Wrapper to make Ollama agent compatible with AgentPool."""

                    def __init__(self, ollama: OllamaAgent):
                        config = AgentConfig(
                            name="llama-3.3",
                            model="llama3.3",
                            context_window=128_000,
                            max_output=4096,
                            cost_per_1k_input=0.0,  # FREE
                            cost_per_1k_output=0.0
                        )
                        super().__init__(config)
                        self.ollama = ollama

                    async def generate(self, prompt: str, **kwargs) -> dict:
                        """Generate using Ollama."""
                        result = self.ollama.generate_with_metadata(prompt, **kwargs)
                        return {
                            "output": result["output"],
                            "tokens_input": result["tokens"]["input"],
                            "tokens_output": result["tokens"]["output"],
                            "cost": 0.0,
                            "model_version": "llama3.3",
                            "metadata": result
                        }

                wrapped = OllamaWrapper(ollama_agent)
                pool.register_agent("llama-3.3", wrapped, enabled=True)
                logger.info("Registered Llama 3.3 (local, FREE)")
        else:
            logger.warning("Ollama not running, local models unavailable")

    # ========================================================================
    # Chinese Providers (if enabled)
    # ========================================================================

    if enable_chinese:
        # DeepSeek Chat V3
        if os.getenv("DEEPSEEK_API_KEY"):
            config = AgentConfig(
                name="deepseek-chat",
                model="deepseek-chat",
                api_key=os.getenv("DEEPSEEK_API_KEY"),
                base_url="https://api.deepseek.com/v1",
                context_window=64_000,
                max_output=4096,
                cost_per_1k_input=0.00014,  # $0.14 per million (extremely cheap)
                cost_per_1k_output=0.00028,  # $0.28 per million
                timeout=120
            )
            agent = MockCloudAgent(config)
            pool.register_agent("deepseek-chat", agent, enabled=True)
            logger.info("Registered DeepSeek Chat (mock)")

    # Log summary
    enabled = pool.list_agents(enabled_only=True)
    total = pool.list_agents(enabled_only=False)
    logger.info(f"Agent pool initialized: {len(enabled)} enabled / {len(total)} total")
    logger.info(f"Available agents: {', '.join(enabled)}")

    return pool


def create_default_agent_pool() -> AgentPool:
    """Create agent pool with default configuration.

    Enables:
    - Cloud providers (if API keys available)
    - Local Ollama (if running)
    - No Chinese providers

    Returns:
        Configured AgentPool
    """
    return create_agent_pool(
        enable_cloud=True,
        enable_local=True,
        enable_chinese=False
    )
